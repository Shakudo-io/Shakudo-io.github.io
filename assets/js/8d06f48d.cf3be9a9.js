"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4538],{3905:function(e,t,n){n.d(t,{Zo:function(){return d},kt:function(){return c}});var a=n(7294);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function r(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},d=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},u=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,l=e.originalType,s=e.parentName,d=r(e,["components","mdxType","originalType","parentName"]),u=p(n),c=i,k=u["".concat(s,".").concat(c)]||u[c]||m[c]||l;return n?a.createElement(k,o(o({ref:t},d),{},{components:n})):a.createElement(k,o({ref:t},d))}));function c(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var l=n.length,o=new Array(l);o[0]=u;var r={};for(var s in t)hasOwnProperty.call(t,s)&&(r[s]=t[s]);r.originalType=e,r.mdxType="string"==typeof e?e:i,o[1]=r;for(var p=2;p<l;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}u.displayName="MDXCreateElement"},6169:function(e,t,n){n.r(t),n.d(t,{assets:function(){return d},contentTitle:function(){return s},default:function(){return c},frontMatter:function(){return r},metadata:function(){return p},toc:function(){return m}});var a=n(7462),i=n(3366),l=(n(7294),n(3905)),o=["components"],r={},s="Triton Inference Server",p={unversionedId:"developer-docs/features/triton-inference-server",id:"developer-docs/features/triton-inference-server",title:"Triton Inference Server",description:"Overview",source:"@site/docs/developer-docs/features/triton-inference-server.md",sourceDirName:"developer-docs/features",slug:"/developer-docs/features/triton-inference-server",permalink:"/developer-docs/features/triton-inference-server",draft:!1,tags:[],version:"current",lastUpdatedBy:"yevgeniy-ds",lastUpdatedAt:1761081717,formattedLastUpdatedAt:"10/21/2025",frontMatter:{},sidebar:"tutorialSidebar",previous:{title:"Traffic Shifting",permalink:"/developer-docs/features/traffic-shifting"},next:{title:"Tutorials",permalink:"/developer-docs/features/tutorials"}},d={},m=[{value:"Overview",id:"overview",level:2},{value:"Access &amp; Location",id:"access--location",level:2},{value:"Key Capabilities",id:"key-capabilities",level:2},{value:"Server Health Monitoring",id:"server-health-monitoring",level:3},{value:"Model Management",id:"model-management",level:3},{value:"Endpoint Management",id:"endpoint-management",level:3},{value:"Real-time Logs",id:"real-time-logs",level:3},{value:"User Interface",id:"user-interface",level:2},{value:"Main View",id:"main-view",level:3},{value:"Dialogs &amp; Modals",id:"dialogs--modals",level:3},{value:"Tables &amp; Data Grids",id:"tables--data-grids",level:3},{value:"Technical Details",id:"technical-details",level:2},{value:"GraphQL Operations",id:"graphql-operations",level:3},{value:"REST API Endpoints",id:"rest-api-endpoints",level:3},{value:"Component Structure",id:"component-structure",level:3},{value:"Context &amp; Configuration",id:"context--configuration",level:3},{value:"Common Workflows",id:"common-workflows",level:2},{value:"Deploying a New Model",id:"deploying-a-new-model",level:3},{value:"Creating a Model Serving Endpoint",id:"creating-a-model-serving-endpoint",level:3},{value:"Managing Server Resources",id:"managing-server-resources",level:3},{value:"Troubleshooting Failed Endpoints",id:"troubleshooting-failed-endpoints",level:3},{value:"Related Features",id:"related-features",level:2},{value:"Notes &amp; Tips",id:"notes--tips",level:2},{value:"Model Repository Best Practices",id:"model-repository-best-practices",level:3},{value:"Performance Optimization",id:"performance-optimization",level:3},{value:"Endpoint Configuration",id:"endpoint-configuration",level:3},{value:"Multi-Model and Ensemble Serving",id:"multi-model-and-ensemble-serving",level:3},{value:"Log Monitoring",id:"log-monitoring",level:3},{value:"Health Checks",id:"health-checks",level:3},{value:"Troubleshooting",id:"troubleshooting",level:3}],u={toc:m};function c(e){var t=e.components,n=(0,i.Z)(e,o);return(0,l.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("h1",{id:"triton-inference-server"},"Triton Inference Server"),(0,l.kt)("h2",{id:"overview"},"Overview"),(0,l.kt)("p",null,"The Triton Inference Server panel provides a comprehensive interface for managing NVIDIA Triton Inference Server deployments within the Shakudo Platform. This feature enables users to monitor server health, manage AI model loading/unloading, and control serving endpoints for production machine learning inference workloads. Triton supports models from any framework (TensorFlow, PyTorch, ONNX, TensorRT, or custom) and can be deployed on GPU or CPU infrastructure."),(0,l.kt)("h2",{id:"access--location"},"Access & Location"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Route"),": ",(0,l.kt)("inlineCode",{parentName:"li"},"?panel=triton-inference-server")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Navigation"),": Main Navigation \u2192 Triton Inference Server"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Access Requirements"),": None specified (standard user access)"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Feature Flags"),": None")),(0,l.kt)("h2",{id:"key-capabilities"},"Key Capabilities"),(0,l.kt)("h3",{id:"server-health-monitoring"},"Server Health Monitoring"),(0,l.kt)("p",null,"The panel continuously monitors the Triton Inference Server health status by checking the ",(0,l.kt)("inlineCode",{parentName:"p"},"/v2/health/ready")," endpoint. A visual indicator (green/red circle) displays whether the server is healthy and ready to serve requests."),(0,l.kt)("h3",{id:"model-management"},"Model Management"),(0,l.kt)("p",null,"Users can view all models in the Triton model repository and control their loading state. Models can be individually loaded or unloaded from the server's memory, or bulk operations can load/unload all models simultaneously. This allows for efficient resource management when multiple models are available."),(0,l.kt)("h3",{id:"endpoint-management"},"Endpoint Management"),(0,l.kt)("p",null,"The panel tracks active Triton serving endpoints (pipeline jobs) that are currently running. Users can view endpoint details, check their health status, and cancel endpoints when needed. Each endpoint represents a running service that exposes model inference capabilities via HTTP/HTTPS."),(0,l.kt)("h3",{id:"real-time-logs"},"Real-time Logs"),(0,l.kt)("p",null,"Both server-level logs and endpoint-specific logs are available in dedicated panels, providing visibility into model operations, inference requests, and system events."),(0,l.kt)("h2",{id:"user-interface"},"User Interface"),(0,l.kt)("h3",{id:"main-view"},"Main View"),(0,l.kt)("p",null,"The interface features two primary tabs accessed via chip buttons:"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Models Tab"),": Displays the models table with server logs panel on the side"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Endpoints Tab"),": Shows the endpoints table with endpoint-specific logs panel on the side")),(0,l.kt)("p",null,"A server health indicator is prominently displayed in the header, showing real-time status of the Triton server."),(0,l.kt)("h3",{id:"dialogs--modals"},"Dialogs & Modals"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("strong",{parentName:"li"},"Cancel Endpoint Dialog"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Purpose: Confirm cancellation of a running Triton endpoint"),(0,l.kt)("li",{parentName:"ul"},"Fields: Confirmation message with endpoint ID"),(0,l.kt)("li",{parentName:"ul"},"Actions: Close (abort) or Cancel (confirm deletion)")))),(0,l.kt)("h3",{id:"tables--data-grids"},"Tables & Data Grids"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("strong",{parentName:"p"},"Models Table")),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Columns:",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Model"),": Model name (clickable to copy)"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Version"),": Model version number"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Bucket Path"),": Full path to model in cloud storage (clickable to copy)"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"State"),": Toggle switch showing Loaded/Unloaded status"))),(0,l.kt)("li",{parentName:"ul"},"Actions:",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Load All: Load all available models into server memory"),(0,l.kt)("li",{parentName:"ul"},"Unload All: Unload all models from server memory"),(0,l.kt)("li",{parentName:"ul"},"Refresh: Reload the models list"),(0,l.kt)("li",{parentName:"ul"},"Individual toggle: Load/unload specific models"))),(0,l.kt)("li",{parentName:"ul"},"Filtering: None"),(0,l.kt)("li",{parentName:"ul"},"Pagination: 10 items per page"))),(0,l.kt)("li",{parentName:"ol"},(0,l.kt)("p",{parentName:"li"},(0,l.kt)("strong",{parentName:"p"},"Endpoints Table")),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Columns:",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Name"),": Endpoint name with cancel button (clickable to copy)"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Endpoint"),": Full URL to the serving endpoint (clickable to copy)"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Health"),": Real-time health check indicator"))),(0,l.kt)("li",{parentName:"ul"},"Actions:",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},"Cancel endpoint (X button per row)"),(0,l.kt)("li",{parentName:"ul"},"Refresh: Reload the endpoints list"),(0,l.kt)("li",{parentName:"ul"},"Row click: Select endpoint to view logs"))),(0,l.kt)("li",{parentName:"ul"},"Filtering: Automatically filters to only show active Triton endpoints (excludes cancelled, failed, or completed jobs)"),(0,l.kt)("li",{parentName:"ul"},"Pagination: Server-side pagination with 10 items per page")))),(0,l.kt)("h2",{id:"technical-details"},"Technical Details"),(0,l.kt)("h3",{id:"graphql-operations"},"GraphQL Operations"),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Queries:")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"tritonServices")," - Fetches active Triton pipeline jobs (endpoints) with filtering for jobType='triton' and excluding cancelled/failed/completed jobs. Returns id, jobName, jobType, status, dashboardPrefix, and daskDashboardUrl.")),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Mutations:")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"cancelEndpoint")," - Updates a pipeline job status to 'cancelled' by ID, effectively terminating the endpoint.")),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Subscriptions:"),"\nNone"),(0,l.kt)("h3",{id:"rest-api-endpoints"},"REST API Endpoints"),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Model Operations:")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"POST /api/triton-dashboard/get-models")," - Fetches model repository index from Triton server (",(0,l.kt)("inlineCode",{parentName:"li"},"/v2/repository/index"),")"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"POST /api/triton-dashboard/load-models")," - Loads or unloads a specific model (",(0,l.kt)("inlineCode",{parentName:"li"},"/v2/repository/models/{name}/{action}"),")")),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Server Monitoring:")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"POST /api/triton-dashboard/check-url")," - Health check endpoint validator"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"POST /api/triton-dashboard/logs")," - Retrieves Triton server logs"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"POST /api/triton-dashboard/server-metrics")," - Fetches server performance metrics")),(0,l.kt)("p",null,(0,l.kt)("strong",{parentName:"p"},"Endpoint Operations:")),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"POST /api/triton-dashboard/check-endpoint-status")," - Validates endpoint health"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"POST /api/triton-dashboard/endpoint-logs")," - Retrieves logs for specific endpoints")),(0,l.kt)("h3",{id:"component-structure"},"Component Structure"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Main Component: ",(0,l.kt)("inlineCode",{parentName:"li"},"shakudo-apps/triton-dashboard/components/Panels/TritonPanel.tsx")),(0,l.kt)("li",{parentName:"ul"},"Tables:",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"shakudo-apps/triton-dashboard/components/Tables/TritonModels.tsx")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"shakudo-apps/triton-dashboard/components/Tables/TritonEndpoints.tsx")))),(0,l.kt)("li",{parentName:"ul"},"Dialogs: ",(0,l.kt)("inlineCode",{parentName:"li"},"shakudo-apps/triton-dashboard/components/Dialogs/CancelEndpoint.tsx")),(0,l.kt)("li",{parentName:"ul"},"Toggles: ",(0,l.kt)("inlineCode",{parentName:"li"},"shakudo-apps/triton-dashboard/components/Toggle/LoadUnloadModelToggle.tsx")),(0,l.kt)("li",{parentName:"ul"},"Log Containers:",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"shakudo-apps/triton-dashboard/components/Containers/TritonLogs.tsx")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"shakudo-apps/triton-dashboard/components/Containers/EndpointLogs.tsx"))))),(0,l.kt)("h3",{id:"context--configuration"},"Context & Configuration"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"TritonAppContext"),": Provides server URL and model repository path configuration"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Environment Variables"),":",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("inlineCode",{parentName:"li"},"TRITON_SERVER"),": Base URL for the Triton Inference Server")))),(0,l.kt)("h2",{id:"common-workflows"},"Common Workflows"),(0,l.kt)("h3",{id:"deploying-a-new-model"},"Deploying a New Model"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Upload model checkpoint to the Triton model repository (cloud bucket path: ",(0,l.kt)("inlineCode",{parentName:"li"},"{bucket}/triton-server/model-repository/"),")"),(0,l.kt)("li",{parentName:"ol"},"Structure the model following ",(0,l.kt)("a",{parentName:"li",href:"https://github.com/triton-inference-server/server/blob/main/docs/model_repository.md"},"Triton model repository format")),(0,l.kt)("li",{parentName:"ol"},"Wait for automatic detection or manually refresh the Models tab"),(0,l.kt)("li",{parentName:"ol"},'Toggle the model state from "Unloaded" to "Loaded"'),(0,l.kt)("li",{parentName:"ol"},'Verify the model appears as "Loaded" in the state column')),(0,l.kt)("h3",{id:"creating-a-model-serving-endpoint"},"Creating a Model Serving Endpoint"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Ensure your model is loaded in the Models tab"),(0,l.kt)("li",{parentName:"ol"},"Write a client application using Triton client libraries"),(0,l.kt)("li",{parentName:"ol"},"Wrap the client with FastAPI or Flask"),(0,l.kt)("li",{parentName:"ol"},"Deploy the client as a pipeline job with jobType='triton'"),(0,l.kt)("li",{parentName:"ol"},"Monitor the endpoint in the Endpoints tab"),(0,l.kt)("li",{parentName:"ol"},"Use the provided URL to make inference requests")),(0,l.kt)("h3",{id:"managing-server-resources"},"Managing Server Resources"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Navigate to the Models tab"),(0,l.kt)("li",{parentName:"ol"},"Review which models are currently loaded"),(0,l.kt)("li",{parentName:"ol"},"Unload unused models to free memory using individual toggles"),(0,l.kt)("li",{parentName:"ol"},'Use "Load All" before batch inference operations'),(0,l.kt)("li",{parentName:"ol"},'Use "Unload All" to clear server memory completely')),(0,l.kt)("h3",{id:"troubleshooting-failed-endpoints"},"Troubleshooting Failed Endpoints"),(0,l.kt)("ol",null,(0,l.kt)("li",{parentName:"ol"},"Switch to the Endpoints tab"),(0,l.kt)("li",{parentName:"ol"},"Identify the problematic endpoint"),(0,l.kt)("li",{parentName:"ol"},"Click on the endpoint row to view its logs in the side panel"),(0,l.kt)("li",{parentName:"ol"},"Review logs for error messages"),(0,l.kt)("li",{parentName:"ol"},"If necessary, cancel the endpoint using the X button"),(0,l.kt)("li",{parentName:"ol"},"Fix the underlying issue and redeploy")),(0,l.kt)("h2",{id:"related-features"},"Related Features"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"/developer-docs/features/jobs"},"Immediate Jobs")," - Triton endpoints are managed as pipeline jobs"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"/developer-docs/features/services"},"Services")," - Similar service management for other types of deployments"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"/developer-docs/features/environment-configs"},"Environment Configs")," - Configure compute resources for Triton deployments")),(0,l.kt)("h2",{id:"notes--tips"},"Notes & Tips"),(0,l.kt)("h3",{id:"model-repository-best-practices"},"Model Repository Best Practices"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Follow the Triton model repository structure strictly to ensure automatic detection"),(0,l.kt)("li",{parentName:"ul"},"For TensorFlow models, ",(0,l.kt)("inlineCode",{parentName:"li"},"config.pbtxt")," can be auto-generated by Triton"),(0,l.kt)("li",{parentName:"ul"},"Model files are stored at: ",(0,l.kt)("inlineCode",{parentName:"li"},"{cloud_bucket}/triton-server/model-repository/")),(0,l.kt)("li",{parentName:"ul"},"Each model should have its own subdirectory with version subdirectories")),(0,l.kt)("h3",{id:"performance-optimization"},"Performance Optimization"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Only keep frequently-used models loaded to optimize memory usage"),(0,l.kt)("li",{parentName:"ul"},"Unload models during low-traffic periods to free resources"),(0,l.kt)("li",{parentName:"ul"},"Use bulk load operations when preparing for batch inference workloads"),(0,l.kt)("li",{parentName:"ul"},"Monitor server health indicator before deploying new endpoints")),(0,l.kt)("h3",{id:"endpoint-configuration"},"Endpoint Configuration"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Custom URL endpoints can be specified during client deployment"),(0,l.kt)("li",{parentName:"ul"},"Inference endpoints typically follow pattern: ",(0,l.kt)("inlineCode",{parentName:"li"},"https://{domain}/hyperplane.dev/{endpoint_name}/infer/")),(0,l.kt)("li",{parentName:"ul"},"Endpoints require the ",(0,l.kt)("inlineCode",{parentName:"li"},"daskDashboardUrl")," field to appear in the endpoints table")),(0,l.kt)("h3",{id:"multi-model-and-ensemble-serving"},"Multi-Model and Ensemble Serving"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Multiple models can be loaded simultaneously and served from a single endpoint"),(0,l.kt)("li",{parentName:"ul"},"Parameterize client inference functions with ",(0,l.kt)("inlineCode",{parentName:"li"},"model_name")," for multi-model endpoints"),(0,l.kt)("li",{parentName:"ul"},"Ensemble models use the ",(0,l.kt)("inlineCode",{parentName:"li"},"ensemble")," platform in ",(0,l.kt)("inlineCode",{parentName:"li"},"config.pbtxt")," with ",(0,l.kt)("inlineCode",{parentName:"li"},"ensemble_scheduling")," configuration"),(0,l.kt)("li",{parentName:"ul"},"Ensemble models can execute multiple models concurrently using Python backend with ",(0,l.kt)("inlineCode",{parentName:"li"},"asyncio"))),(0,l.kt)("h3",{id:"log-monitoring"},"Log Monitoring"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Server logs (left panel in Models tab) show server-level events and model loading operations"),(0,l.kt)("li",{parentName:"ul"},"Endpoint logs (right panel in Endpoints tab) show request-specific logs for selected endpoints"),(0,l.kt)("li",{parentName:"ul"},"Click on any endpoint row to switch the log view to that specific endpoint")),(0,l.kt)("h3",{id:"health-checks"},"Health Checks"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"Server health is checked via ",(0,l.kt)("inlineCode",{parentName:"li"},"/v2/health/ready")," endpoint"),(0,l.kt)("li",{parentName:"ul"},"Individual endpoint health indicators appear in the Health column"),(0,l.kt)("li",{parentName:"ul"},"Green indicator = healthy and ready, Red indicator = unhealthy or not ready")),(0,l.kt)("h3",{id:"troubleshooting"},"Troubleshooting"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},"If models don't appear after upload, check the model repository structure and refresh"),(0,l.kt)("li",{parentName:"ul"},"If load/unload operations fail, verify server health and check server logs"),(0,l.kt)("li",{parentName:"ul"},"Endpoint cancellation changes job status but doesn't immediately terminate running processes"),(0,l.kt)("li",{parentName:"ul"},"Failed endpoints remain visible until explicitly filtered or cancelled")))}c.isMDXComponent=!0}}]);